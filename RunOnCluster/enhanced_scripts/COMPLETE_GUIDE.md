# ğŸ‰ Complete Individual Model Scripts - Ready to Use!

## âœ… What You Have: ALL 14 Models + Batch Scripts

### ğŸ“„ Python Scripts (14)
Each runs ONE model on all 4 experiments with detailed tracking:

**Statistical (3):**
- `enhanced_02a_prophet.py` â†’ `enhanced_02a_prophet.sh`
- `enhanced_02b_tbats.py` â†’ `enhanced_02b_tbats.sh`
- `enhanced_02c_sarimax.py` â†’ `enhanced_02c_sarimax.sh`

**Machine Learning (3):**
- `enhanced_03a_xgboost.py` â†’ `enhanced_03a_xgboost.sh`
- `enhanced_03b_lightgbm.py` â†’ `enhanced_03b_lightgbm.sh`
- `enhanced_03c_catboost.py` â†’ `enhanced_03c_catboost.sh`

**Deep Learning (3):**
- `enhanced_04a_nhits.py` â†’ `enhanced_04a_nhits.sh`
- `enhanced_04b_tft.py` â†’ `enhanced_04b_tft.sh`
- `enhanced_04c_patchtst.py` â†’ `enhanced_04c_patchtst.sh`

**Literature (2):**
- `enhanced_05a_mcd30.py` â†’ `enhanced_05a_mcd30.sh`
- `enhanced_05b_lear.py` â†’ `enhanced_05b_lear.sh`

**Legacy (3):**
- `enhanced_06a_random_forest.py` â†’ `enhanced_06a_random_forest.sh`
- `enhanced_06b_run_lstm_only.py` â†’ `enhanced_06b_lstm.sh`
- `enhanced_06c_cnn_lstm.py` â†’ `enhanced_06c_cnn_lstm.sh`

### ğŸ”§ Master Submission Scripts (3)
- **`submit_all_14_models.sh`** - Submit ALL 14 models in parallel
- **`submit_missing_5_models.sh`** - Submit only the 5 missing models
- **`submit_by_category.sh`** - Template for category-based submission

### ğŸ“Š Analysis Tools (2)
- **`utils_detailed_metrics.py`** - Core tracking utilities
- **`analyze_detailed_results.py`** - Comprehensive analysis

---

## ğŸš€ Quick Start - Run Missing Models

### On the Cluster:

```bash
cd /home/hu/hu_hu/hu_elnaab01/projects/my_project/Bachelor_project/RunOnCluster/enhanced_scripts

# Option 1: Submit the 5 missing models
bash submit_missing_5_models.sh

# Option 2: Submit all 14 models (fresh run)
bash submit_all_14_models.sh

# Monitor
squeue --me
```

### On Your Local Machine:

```bash
cd enhanced_scripts

# Run missing models
python enhanced_02b_tbats.py &
python enhanced_02c_sarimax.py &
python enhanced_04b_tft.py &
python enhanced_04c_patchtst.py &
python enhanced_06b_run_lstm_only.py &
wait
```

---

## ğŸ“‹ Expected Output

### After Running Missing 5 Models:

**New Standard Results:**
- `../outputs/results_tbats.txt` â­
- `../outputs/results_sarimax.txt` â­
- `../outputs/results_tft.txt` â­
- `../outputs/results_patchtst.txt` â­
- `../outputs/results_lstm.txt` â­

**New Detailed Results:**
- `../detailed_results/tbats_with_wsi_solar.csv` (+ 3 more experiments)
- `../detailed_results/sarimax_with_wsi_solar.csv` (+ 3 more)
- `../detailed_results/tft_with_wsi_solar.csv` (+ 3 more)
- `../detailed_results/patchtst_with_wsi_solar.csv` (+ 3 more)
- `../detailed_results/lstm_with_wsi_solar.csv` (+ 3 more)
- `../detailed_results/all_predictions.csv` (master file with ALL)

Total: **20 new CSV files** (5 models Ã— 4 experiments)

---

## âš¡ Performance Comparison

### Sequential (old approach)
```
Model 1: 2.5h
Model 2: 2.5h
Model 3: 2.5h
Model 4: 2.5h
Model 5: 2.5h
--------------
TOTAL: 12.5 hours
```

### Parallel (new approach)
```
All 5 models run simultaneously
Longest: ~3 hours
--------------
TOTAL: 3 hours (4x faster!)
```

---

## ğŸ“Š Analysis After Completion

Once all models finish:

```bash
# Run comprehensive analysis
python analyze_detailed_results.py
```

This generates:
- Model rankings
- Experiment winners
- Error distributions
- Worst predictions
- Summary statistics
- Comprehensive reports

---

## ğŸ¯ Submission Commands Reference

### Individual Model Submission
```bash
sbatch enhanced_02a_prophet.sh
sbatch enhanced_03a_xgboost.sh
# ... etc
```

### Category Submission
```bash
# All Statistical
sbatch enhanced_02a_prophet.sh
sbatch enhanced_02b_tbats.sh
sbatch enhanced_02c_sarimax.sh

# All ML
sbatch enhanced_03a_xgboost.sh
sbatch enhanced_03b_lightgbm.sh
sbatch enhanced_03c_catboost.sh

# All DL
sbatch enhanced_04a_nhits.sh
sbatch enhanced_04b_tft.sh
sbatch enhanced_04c_patchtst.sh
```

### Master Submission
```bash
# Submit all 14 at once
bash submit_all_14_models.sh

# Submit only missing 5
bash submit_missing_5_models.sh
```

---

## ğŸ“ Complete File Structure

```
enhanced_scripts/
â”œâ”€â”€ Python Scripts (14) - One per model
â”‚   â”œâ”€â”€ enhanced_02a_prophet.py
â”‚   â”œâ”€â”€ enhanced_02b_tbats.py
â”‚   â”œâ”€â”€ enhanced_02c_sarimax.py
â”‚   â”œâ”€â”€ enhanced_03a_xgboost.py
â”‚   â”œâ”€â”€ enhanced_03b_lightgbm.py
â”‚   â”œâ”€â”€ enhanced_03c_catboost.py
â”‚   â”œâ”€â”€ enhanced_04a_nhits.py
â”‚   â”œâ”€â”€ enhanced_04b_tft.py
â”‚   â”œâ”€â”€ enhanced_04c_patchtst.py
â”‚   â”œâ”€â”€ enhanced_05a_mcd30.py
â”‚   â”œâ”€â”€ enhanced_05b_lear.py
â”‚   â”œâ”€â”€ enhanced_06a_random_forest.py
â”‚   â”œâ”€â”€ enhanced_06b_run_lstm_only.py
â”‚   â””â”€â”€ enhanced_06c_cnn_lstm.py
â”‚
â”œâ”€â”€ Batch Scripts (14) - One per model
â”‚   â”œâ”€â”€ enhanced_02a_prophet.sh
â”‚   â”œâ”€â”€ enhanced_02b_tbats.sh
â”‚   â”œâ”€â”€ enhanced_02c_sarimax.sh
â”‚   â”œâ”€â”€ enhanced_03a_xgboost.sh
â”‚   â”œâ”€â”€ enhanced_03b_lightgbm.sh
â”‚   â”œâ”€â”€ enhanced_03c_catboost.sh
â”‚   â”œâ”€â”€ enhanced_04a_nhits.sh
â”‚   â”œâ”€â”€ enhanced_04b_tft.sh
â”‚   â”œâ”€â”€ enhanced_04c_patchtst.sh
â”‚   â”œâ”€â”€ enhanced_05a_mcd30.sh
â”‚   â”œâ”€â”€ enhanced_05b_lear.sh
â”‚   â”œâ”€â”€ enhanced_06a_random_forest.sh
â”‚   â”œâ”€â”€ enhanced_06b_lstm.sh
â”‚   â””â”€â”€ enhanced_06c_cnn_lstm.sh
â”‚
â”œâ”€â”€ Master Submission Scripts (3)
â”‚   â”œâ”€â”€ submit_all_14_models.sh
â”‚   â”œâ”€â”€ submit_missing_5_models.sh
â”‚   â””â”€â”€ submit_by_category.sh
â”‚
â”œâ”€â”€ Analysis Tools (2)
â”‚   â”œâ”€â”€ utils_detailed_metrics.py
â”‚   â””â”€â”€ analyze_detailed_results.py
â”‚
â””â”€â”€ Documentation (2)
    â”œâ”€â”€ COMPLETE_GUIDE.md (this file)
    â””â”€â”€ generate_individual_scripts.py

TOTAL: 35 files
```

---

## ğŸ¯ Recommended Workflow

### Step 1: Push to GitHub
```bash
cd /d/Bachelor\ abroad/
git add RunOnCluster/enhanced_scripts/
git commit -m "Add all 14 individual model scripts with detailed tracking"
git push
```

### Step 2: On Cluster - Pull Changes
```bash
cd /home/hu/hu_hu/hu_elnaab01/projects/my_project/Bachelor_project/
git pull
cd RunOnCluster/enhanced_scripts
```

### Step 3: Submit Missing Models
```bash
# Make scripts executable
chmod +x *.sh

# Submit missing 5 models
bash submit_missing_5_models.sh

# OR submit all 14 for a fresh run
bash submit_all_14_models.sh
```

### Step 4: Monitor Progress
```bash
# Check job status
squeue --me

# Check outputs (as they complete)
ls -lh *.out
ls -lh *.err

# Check results folder
ls -lh ../outputs/
ls -lh ../detailed_results/
```

### Step 5: Analyze Results
```bash
# After all complete
python analyze_detailed_results.py

# Check comprehensive reports
ls -lh ../detailed_results/
cat ../detailed_results/summary_report.txt
```

---

## ğŸ” Monitoring Individual Jobs

```bash
# List all your jobs
squeue --me

# Check specific job output
cat prophet.out
cat tbats.err

# Follow a job in real-time
tail -f xgboost.out
```

---

## âš ï¸ Troubleshooting

### If a job fails:
```bash
# Check error file
cat {model}.err

# Check output file
cat {model}.out

# Resubmit just that model
sbatch enhanced_0Xx_{model}.sh
```

### If all jobs fail:
```bash
# Check conda path
which conda
echo $CONDA_EXE

# Check if data exists
ls -lh ../processed_data/

# Test one model locally first
python enhanced_03a_xgboost.py
```

---

## ğŸ“Š What Gets Saved

### For Each Model Ã— Each Experiment:

**Standard Results** (`../outputs/`):
- Aggregated metrics (MAE, RMSE, RÂ²)
- Best hyperparameters
- Timestamp
- Text format for easy reading

**Detailed Results** (`../detailed_results/`):
- Every single prediction (1750+ rows per experiment)
- Actual vs predicted values
- Residuals (errors per sample)
- Absolute errors
- Squared errors
- Percentage errors
- Hyperparameters
- Metadata
- CSV format for analysis

---

## ğŸ‰ Final Checklist

Before submitting:
- âœ… All 14 Python scripts created
- âœ… All 14 batch scripts created
- âœ… Master submission scripts created
- âœ… Utils and analysis tools in place
- âœ… Documentation complete

After submission:
- â³ Monitor with `squeue --me`
- â³ Check outputs as jobs complete
- â³ Run analysis after all finish
- â³ Review detailed_results/

---

## ğŸ’¡ Tips

1. **Run missing 5 first** to complete your analysis quickly
2. **Monitor stderr files** for early error detection
3. **Use parallel execution** for maximum speedup
4. **Analyze incrementally** as models complete
5. **Keep detailed_results** for future research

---

## ğŸš€ Summary

**YOU HAVE:**
- âœ… 14 individual model scripts (100% coverage)
- âœ… 14 batch submission scripts
- âœ… 3 master submission scripts
- âœ… Complete analysis toolchain
- âœ… Detailed residuals tracking for every prediction

**READY TO:**
- Submit all models in parallel
- Complete your missing models
- Generate comprehensive analysis
- Track every prediction in detail

**SPEEDUP:**
- 11.7x faster than sequential
- ~3 hours instead of ~35 hours

---

**All files ready in: `enhanced_scripts/` folder**

**To start:** `bash submit_missing_5_models.sh` ğŸš€

